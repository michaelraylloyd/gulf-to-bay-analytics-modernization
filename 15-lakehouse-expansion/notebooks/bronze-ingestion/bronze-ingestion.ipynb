{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cd9bbf8",
   "metadata": {},
   "source": [
    "# Bronze Ingestion Notebook\n",
    "\n",
    "This notebook performs deterministic ingestion of raw source data into the Bronze layer of the Lakehouse. It enforces schema typing, applies minimal transformations, and writes append‑only Delta outputs suitable for downstream validation and enrichment. The Bronze layer preserves raw fidelity while ensuring consistent structure for all subsequent processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ec4e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Bronze Ingestion Notebook\n",
    "# Deterministic raw → bronze ingestion with schema enforcement\n",
    "# ============================================================\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1. Imports\n",
    "# ------------------------------------------------------------\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import (\n",
    "    StructType, StructField, StringType, IntegerType, DoubleType, TimestampType\n",
    ")\n",
    "from pyspark.sql.functions import current_timestamp\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2. Define canonical Bronze schema\n",
    "#    (Replace fields as needed for your actual source)\n",
    "# ------------------------------------------------------------\n",
    "bronze_schema = StructType([\n",
    "    StructField(\"order_id\", StringType(), True),\n",
    "    StructField(\"customer_id\", StringType(), True),\n",
    "    StructField(\"product_id\", StringType(), True),\n",
    "    StructField(\"quantity\", IntegerType(), True),\n",
    "    StructField(\"unit_price\", DoubleType(), True),\n",
    "    StructField(\"order_timestamp\", TimestampType(), True)\n",
    "])\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3. Define input and output paths\n",
    "#    (ASCII‑safe placeholders; replace with real paths later)\n",
    "# ------------------------------------------------------------\n",
    "raw_input_path = \"/mnt/raw/sales/\"\n",
    "bronze_output_path = \"/mnt/bronze/sales/\"\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4. Read raw data with enforced schema\n",
    "# ------------------------------------------------------------\n",
    "df_raw = (\n",
    "    spark.read\n",
    "         .format(\"json\")\n",
    "         .schema(bronze_schema)\n",
    "         .load(raw_input_path)\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5. Add ingestion metadata\n",
    "# ------------------------------------------------------------\n",
    "df_bronze = (\n",
    "    df_raw.withColumn(\"ingestion_timestamp\", current_timestamp())\n",
    "          .withColumn(\"source_file\", current_timestamp().cast(\"string\"))\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 6. Write to Bronze as append‑only Delta\n",
    "# ------------------------------------------------------------\n",
    "(\n",
    "    df_bronze.write\n",
    "             .format(\"delta\")\n",
    "             .mode(\"append\")\n",
    "             .save(bronze_output_path)\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 7. Confirmation\n",
    "# ------------------------------------------------------------\n",
    "print(\"Bronze ingestion completed successfully.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
