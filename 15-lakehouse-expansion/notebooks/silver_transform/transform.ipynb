{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e5aa71c",
   "metadata": {},
   "source": [
    "# Silver Transformation Notebook\n",
    "\n",
    "This notebook refines Bronze data into the Silver layer by applying deterministic cleaning, normalization, and deduplication rules. It enforces the canonical Silver schema, resolves data quality issues, and prepares the dataset for analytical modeling in the Gold layer.\n",
    "\n",
    "The transformation process is intentionally minimal and predictable: it standardizes types, removes invalid or duplicate records, and applies structural normalization without introducing business logic. All environment‑specific values are externalized through configuration, and the notebook mirrors the logic used by the pipeline‑ready script to ensure consistent execution across development and automation paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11913eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Silver Transformation Notebook\n",
    "# Deterministic Bronze → Silver refinement\n",
    "# ============================================================\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1. Initialize Spark\n",
    "# ------------------------------------------------------------\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, trim, lower, current_timestamp\n",
    "from pyspark.sql.types import (\n",
    "    StructType, StructField, StringType, IntegerType, DoubleType, TimestampType\n",
    ")\n",
    "import json\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2. Load configuration\n",
    "# ------------------------------------------------------------\n",
    "config_path = \"/Workspace/Repos/silver/silver-transform-config.json\"\n",
    "\n",
    "with open(config_path, \"r\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "bronze_path = config[\"paths\"][\"bronze\"]\n",
    "silver_path = config[\"paths\"][\"silver\"]\n",
    "silver_mode = config[\"write\"][\"mode\"]\n",
    "schema_file = config[\"schema\"][\"file\"]\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3. Load Silver schema\n",
    "# ------------------------------------------------------------\n",
    "with open(schema_file, \"r\") as f:\n",
    "    schema_json = json.load(f)\n",
    "\n",
    "silver_schema = StructType([\n",
    "    StructField(\"order_id\", StringType(), True),\n",
    "    StructField(\"customer_id\", StringType(), True),\n",
    "    StructField(\"product_id\", StringType(), True),\n",
    "    StructField(\"quantity\", IntegerType(), True),\n",
    "    StructField(\"unit_price\", DoubleType(), True),\n",
    "    StructField(\"order_timestamp\", TimestampType(), True),\n",
    "    StructField(\"total_amount\", DoubleType(), True)\n",
    "])\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4. Read Bronze data\n",
    "# ------------------------------------------------------------\n",
    "df_bronze = (\n",
    "    spark.read\n",
    "         .format(\"delta\")\n",
    "         .load(bronze_path)\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5. Apply deterministic Silver transformations\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# Clean and normalize fields\n",
    "df_clean = (\n",
    "    df_bronze\n",
    "        .withColumn(\"order_id\", trim(col(\"order_id\")))\n",
    "        .withColumn(\"customer_id\", trim(col(\"customer_id\")))\n",
    "        .withColumn(\"product_id\", trim(col(\"product_id\")))\n",
    "        .withColumn(\"quantity\", col(\"quantity\").cast(\"int\"))\n",
    "        .withColumn(\"unit_price\", col(\"unit_price\").cast(\"double\"))\n",
    "        .withColumn(\"total_amount\", col(\"quantity\") * col(\"unit_price\"))\n",
    ")\n",
    "\n",
    "# Deduplicate records\n",
    "df_deduped = df_clean.dropDuplicates([\"order_id\", \"product_id\", \"order_timestamp\"])\n",
    "\n",
    "# Enforce Silver schema\n",
    "df_silver = spark.createDataFrame(df_deduped.rdd, silver_schema)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 6. Write to Silver\n",
    "# ------------------------------------------------------------\n",
    "(\n",
    "    df_silver.write\n",
    "             .format(\"delta\")\n",
    "             .mode(silver_mode)\n",
    "             .save(silver_path)\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 7. Confirmation\n",
    "# ------------------------------------------------------------\n",
    "print(\"Silver transformation completed successfully.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
