{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ae35416",
   "metadata": {},
   "source": [
    "# Data Quality Check — Sales Table\n",
    "\n",
    "This notebook executes the Data Quality framework for the `sales` table as part of the Lakehouse Expansion engineering pillar. It loads the table, applies expectations defined in `sales_expectations.json`, evaluates the results using the shared `dq_runner.py` module, and produces a structured report suitable for downstream monitoring, alerting, or pipeline enforcement.\n",
    "\n",
    "The workflow is intentionally consolidated into a single execution block to keep the notebook clean, readable, and aligned with production engineering practices. All operational steps—loading data, importing the runner, executing checks, formatting results, saving outputs, and enforcing failure rules—are performed within one Python cell for deterministic execution and minimal cognitive overhead.\n",
    "\n",
    "This notebook is designed to be pipeline‑ready, environment‑agnostic, and easily extended to additional tables as the Lakehouse Expansion continues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009e7c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 — Load sales table\n",
    "df = spark.read.table(\"lakehouse.sales\").toPandas()\n",
    "\n",
    "# Step 2 — Add module path and import runner\n",
    "import sys\n",
    "sys.path.append(\"/lakehouse/default/Files/15-lakehouse-expansion/features/data-quality\")\n",
    "from dq_runner import run_dq\n",
    "\n",
    "# Step 3 — Define expectations path\n",
    "expectations_path = \"/lakehouse/default/Files/15-lakehouse-expansion/features/data-quality/expectations/sales_expectations.json\"\n",
    "\n",
    "# Step 4 — Run data quality checks\n",
    "results = run_dq(\n",
    "    table_df=df,\n",
    "    expectations_path=expectations_path\n",
    ")\n",
    "\n",
    "# Step 5 — Convert results to DataFrame\n",
    "import pandas as pd\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Step 6 — Display results\n",
    "results_df\n",
    "\n",
    "# Step 7 — Optional: Save report\n",
    "results_df.to_csv(\n",
    "    \"/lakehouse/default/Files/15-lakehouse-expansion/features/data-quality/dq_report_sales.csv\",\n",
    "    index=False\n",
    ")\n",
    "\n",
    "# Step 8 — Optional: Fail notebook if checks failed\n",
    "failed = [r for r in results if not r[\"passed\"]]\n",
    "if failed:\n",
    "    raise Exception(\"One or more Data Quality checks failed.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
